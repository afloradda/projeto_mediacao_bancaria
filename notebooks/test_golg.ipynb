{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dde58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Teste Gold DAG - Primeira vers√£o\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from gold_clipping import gold_dag\n",
    "\n",
    "print(\"Testando Gold DAG...\")\n",
    "\n",
    "try:\n",
    "    result = gold_dag()\n",
    "    print(\"‚úÖ Gold DAG: SUCESSO!\")\n",
    "\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" Erro: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a80b402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 13:28:30,247 - INFO -  Iniciando DAG Gold - Foco S√£o Paulo...\n",
      "2026-02-17 13:28:30,248 - INFO -    Carregando dados da camada Silver...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testando Gold DAG - Recortes S√£o Paulo...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 13:28:42,036 - INFO - ‚úÖ Dados carregados: 2,567,095 registros, 30 colunas\n",
      "2026-02-17 13:28:42,038 - INFO - üîç Verificando cidades de S√£o Paulo...\n",
      "2026-02-17 13:28:42,552 - INFO - üìä Registros SP encontrados: 649,651\n",
      "2026-02-17 13:28:42,609 - INFO - üèôÔ∏è Cidades √∫nicas em SP: 760\n",
      "2026-02-17 13:28:42,611 - WARNING - ‚ö†Ô∏è ATEN√á√ÉO: 760 cidades encontradas (esperado: m√°x 645)\n",
      "2026-02-17 13:28:42,613 - WARNING - ‚ö†Ô∏è Excesso: +115 cidades - poss√≠veis inconsist√™ncias!\n",
      "2026-02-17 13:28:42,616 - WARNING - ‚ö†Ô∏è Cidades com poucos registros (‚â§5): 79\n",
      "2026-02-17 13:28:42,618 - WARNING -    Poss√≠veis erros de digita√ß√£o:\n",
      "2026-02-17 13:28:42,619 - WARNING -       ‚Ä¢ 'Monte Verde Paulista': 5 registros\n",
      "2026-02-17 13:28:42,621 - WARNING -       ‚Ä¢ 'Cafel?ndia': 5 registros\n",
      "2026-02-17 13:28:42,622 - WARNING -       ‚Ä¢ 'Guai?ara': 5 registros\n",
      "2026-02-17 13:28:42,623 - WARNING -       ‚Ä¢ 'Aparecida de Monte Alto': 5 registros\n",
      "2026-02-17 13:28:42,624 - WARNING -       ‚Ä¢ 'Igara√≠': 4 registros\n",
      "2026-02-17 13:28:42,625 - WARNING -       ‚Ä¢ 'Juritis': 4 registros\n",
      "2026-02-17 13:28:42,626 - WARNING -       ‚Ä¢ 'Lageado de Ara√ßa√≠ba': 4 registros\n",
      "2026-02-17 13:28:42,626 - WARNING -       ‚Ä¢ 'Paragua?u Paulista': 4 registros\n",
      "2026-02-17 13:28:42,627 - WARNING -       ‚Ä¢ 'Marcond√©sia': 4 registros\n",
      "2026-02-17 13:28:42,628 - WARNING -       ‚Ä¢ 'Juruc√™': 4 registros\n",
      "2026-02-17 13:28:42,629 - INFO - üìã Top 10 cidades SP:\n",
      "2026-02-17 13:28:42,630 - INFO -    ‚Ä¢ S√£o Paulo: 227,446\n",
      "2026-02-17 13:28:42,631 - INFO -    ‚Ä¢ Guarulhos: 20,522\n",
      "2026-02-17 13:28:42,633 - INFO -    ‚Ä¢ Campinas: 18,330\n",
      "2026-02-17 13:28:42,634 - INFO -    ‚Ä¢ Sorocaba: 14,270\n",
      "2026-02-17 13:28:42,635 - INFO -    ‚Ä¢ Osasco: 13,420\n",
      "2026-02-17 13:28:42,636 - INFO -    ‚Ä¢ S√£o Bernardo do Campo: 13,229\n",
      "2026-02-17 13:28:42,638 - INFO -    ‚Ä¢ Santo Andr√©: 12,996\n",
      "2026-02-17 13:28:42,639 - INFO -    ‚Ä¢ Ribeir√£o Preto: 11,769\n",
      "2026-02-17 13:28:42,640 - INFO -    ‚Ä¢ S√£o Jos√© dos Campos: 11,415\n",
      "2026-02-17 13:28:42,641 - INFO -    ‚Ä¢ Jundia√≠: 8,714\n",
      "2026-02-17 13:28:42,642 - ERROR - ‚ùå Erro no Gold DAG: 'cidade_suspeita'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ana.leandro\\Desktop\\projeto_mediacao_bancaria\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7096, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'cidade_suspeita'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ana.leandro\\AppData\\Local\\Temp\\ipykernel_24580\\1821548390.py\", line 14, in <module>\n",
      "    result = gold_dag()\n",
      "  File \"c:\\Users\\ana.leandro\\Desktop\\projeto_mediacao_bancaria\\notebooks\\../src\\gold_clipping.py\", line 314, in gold_dag\n",
      "    df, validated_sp = verification_sp_cities(df)\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~~^^^^\n",
      "  File \"c:\\Users\\ana.leandro\\Desktop\\projeto_mediacao_bancaria\\notebooks\\../src\\gold_clipping.py\", line 75, in verification_sp_cities\n",
      "    suspicious_sp = sp_data[sp_data['cidade_suspeita'] == True]\n",
      "                            ~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ana.leandro\\Desktop\\projeto_mediacao_bancaria\\env\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4113, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"c:\\Users\\ana.leandro\\Desktop\\projeto_mediacao_bancaria\\env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3819, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'cidade_suspeita'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Erro no teste: 'cidade_suspeita'\n",
      "\n",
      "============================================================\n",
      "üèÅ Teste Gold DAG conclu√≠do!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Teste completo do Gold DAG - Recortes SP\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from gold_clipping import gold_dag\n",
    "\n",
    "print(\"üß™ Testando Gold DAG - Recortes S√£o Paulo...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    result = gold_dag()\n",
    "    print(\"‚úÖ Gold DAG: SUCESSO!\")\n",
    "    \n",
    "    # Verificar arquivos gerados\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    \n",
    "    gold_path = Path(\"../data/gold\")\n",
    "    \n",
    "    if gold_path.exists():\n",
    "        gold_files = list(gold_path.glob(\"*.csv\"))\n",
    "        print(f\"\\nüìÅ Arquivos Gold gerados: {len(gold_files)}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for file in sorted(gold_files):\n",
    "            size_mb = file.stat().st_size / (1024*1024)\n",
    "            print(f\"   üìÑ {file.name}: {size_mb:.1f} MB\")\n",
    "        \n",
    "        # An√°lise detalhada dos principais arquivos\n",
    "        print(f\"\\nüìä AN√ÅLISE DETALHADA DOS RECORTES:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 1. Dataset principal SP\n",
    "        main_file = gold_path / \"sp_consumidor_completo_v1.csv\"\n",
    "        if main_file.exists():\n",
    "            df_main = pd.read_csv(main_file, sep=';', nrows=1000)  # Sample\n",
    "            print(f\"üèôÔ∏è Dataset Principal SP:\")\n",
    "            print(f\"   ‚Ä¢ Colunas: {len(df_main.columns)}\")\n",
    "            print(f\"   ‚Ä¢ Amostra shape: {df_main.shape}\")\n",
    "            \n",
    "            if 'is_agibank' in df_main.columns:\n",
    "                agibank_sample = (df_main['is_agibank'] == True).sum()\n",
    "                print(f\"   ‚Ä¢ Agibank na amostra: {agibank_sample}\")\n",
    "        \n",
    "        # 2. Ranking de cidades\n",
    "        ranking_file = gold_path / \"sp_ranking_cidades_v1.csv\"\n",
    "        if ranking_file.exists():\n",
    "            df_ranking = pd.read_csv(ranking_file)\n",
    "            print(f\"\\nüó∫Ô∏è Ranking Cidades SP:\")\n",
    "            print(f\"   ‚Ä¢ Total cidades: {len(df_ranking)}\")\n",
    "            print(f\"   ‚Ä¢ Colunas: {list(df_ranking.columns)}\")\n",
    "            print(f\"   ‚Ä¢ Top 3 cidades:\")\n",
    "            for i, (city, data) in enumerate(df_ranking.head(3).iterrows()):\n",
    "                print(f\"      {i+1}. {city}: {data['total_reclamacoes']:,} reclama√ß√µes\")\n",
    "        \n",
    "        # 3. An√°lise et√°ria\n",
    "        age_file = gold_path / \"sp_analise_etaria_v1.csv\"\n",
    "        if age_file.exists():\n",
    "            df_age = pd.read_csv(age_file)\n",
    "            print(f\"\\nüë• An√°lise Et√°ria:\")\n",
    "            print(f\"   ‚Ä¢ Faixas et√°rias: {len(df_age)}\")\n",
    "            print(f\"   ‚Ä¢ Top 3 faixas:\")\n",
    "            for i, (age, data) in enumerate(df_age.head(3).iterrows()):\n",
    "                print(f\"      {i+1}. {age}: {data['total_reclamacoes']:,} reclama√ß√µes\")\n",
    "        \n",
    "        # 4. Dataset Agibank\n",
    "        agibank_file = gold_path / \"sp_agibank_only_v1.csv\"\n",
    "        if agibank_file.exists():\n",
    "            # S√≥ ler header para verificar\n",
    "            df_agibank_info = pd.read_csv(agibank_file, sep=';', nrows=0)\n",
    "            print(f\"\\nüè¶ Dataset Agibank SP:\")\n",
    "            print(f\"   ‚Ä¢ Arquivo existe: ‚úÖ\")\n",
    "            print(f\"   ‚Ä¢ Colunas: {len(df_agibank_info.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüéâ Todos os recortes foram gerados com sucesso!\")\n",
    "        print(f\"üìÇ Localiza√ß√£o: {gold_path.absolute()}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Diret√≥rio gold n√£o foi criado!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro no teste: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÅ Teste Gold DAG conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f9cfcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cache limpo!\n"
     ]
    }
   ],
   "source": [
    "# Execute esta c√©lula PRIMEIRO\n",
    "%reset -f\n",
    "\n",
    "# Limpar todos os imports\n",
    "import sys\n",
    "modules_to_remove = [m for m in sys.modules if 'gold_clipping' in m]\n",
    "for module in modules_to_remove:\n",
    "    del sys.modules[module]\n",
    "\n",
    "print(\"‚úÖ Cache limpo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa63344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpa handlers anteriores do logging\n",
    "import logging\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09da44b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 13:55:23,006 - INFO - üöÄ Iniciando DAG Gold - Foco S√£o Paulo...\n",
      "2026-02-17 13:55:23,007 - INFO -    Carregando dados da camada Silver...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testando Gold DAG - Recortes S√£o Paulo...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-17 13:55:35,945 - INFO - ‚úÖ Dados carregados: 2,567,095 registros, 30 colunas\n",
      "2026-02-17 13:55:35,946 - INFO - üîç Verificando cidades de S√£o Paulo...\n",
      "2026-02-17 13:55:36,362 - INFO - üìä Registros SP encontrados: 649,651\n",
      "2026-02-17 13:55:36,414 - INFO - üèôÔ∏è Cidades √∫nicas em SP (antes da limpeza): 760\n",
      "2026-02-17 13:55:36,415 - WARNING - ‚ö†Ô∏è ATEN√á√ÉO: 760 cidades encontradas (esperado: m√°x 645)\n",
      "2026-02-17 13:55:36,416 - WARNING - ‚ö†Ô∏è Excesso: +115 cidades - iniciando limpeza...\n",
      "2026-02-17 13:55:36,416 - INFO - üìã Top 10 cidades SP:\n",
      "2026-02-17 13:55:36,417 - INFO -    ‚Ä¢ S√£o Paulo: 227,446\n",
      "2026-02-17 13:55:36,418 - INFO -    ‚Ä¢ Guarulhos: 20,522\n",
      "2026-02-17 13:55:36,418 - INFO -    ‚Ä¢ Campinas: 18,330\n",
      "2026-02-17 13:55:36,419 - INFO -    ‚Ä¢ Sorocaba: 14,270\n",
      "2026-02-17 13:55:36,419 - INFO -    ‚Ä¢ Osasco: 13,420\n",
      "2026-02-17 13:55:36,420 - INFO -    ‚Ä¢ S√£o Bernardo do Campo: 13,229\n",
      "2026-02-17 13:55:36,420 - INFO -    ‚Ä¢ Santo Andr√©: 12,996\n",
      "2026-02-17 13:55:36,421 - INFO -    ‚Ä¢ Ribeir√£o Preto: 11,769\n",
      "2026-02-17 13:55:36,422 - INFO -    ‚Ä¢ S√£o Jos√© dos Campos: 11,415\n",
      "2026-02-17 13:55:36,422 - INFO -    ‚Ä¢ Jundia√≠: 8,714\n",
      "2026-02-17 13:55:36,423 - INFO - üßπ Limpando cidades de SP...\n",
      "2026-02-17 13:55:36,468 - INFO -    üîß Corrigindo caracteres corrompidos...\n",
      "2026-02-17 13:55:36,512 - INFO -       ‚úÖ 'Cafel?ndia' ‚Üí 'Cafel√¢ndia': 5 registros\n",
      "2026-02-17 13:55:36,558 - INFO -       ‚úÖ 'Guai?ara' ‚Üí 'Guai√ßara': 5 registros\n",
      "2026-02-17 13:55:36,612 - INFO -       ‚úÖ 'Paragua?u Paulista' ‚Üí 'Paragua√ßu Paulista': 4 registros\n",
      "2026-02-17 13:55:36,659 - INFO -       ‚úÖ 'Igara√≠' ‚Üí 'Igara√≠': 4 registros\n",
      "2026-02-17 13:55:36,706 - INFO -       ‚úÖ 'Juritis' ‚Üí 'Juritis': 4 registros\n",
      "2026-02-17 13:55:36,756 - INFO -       ‚úÖ 'Marcond√©sia' ‚Üí 'Marcond√©sia': 4 registros\n",
      "2026-02-17 13:55:36,800 - INFO -       ‚úÖ 'Juruc√™' ‚Üí 'Juruc√™': 4 registros\n",
      "2026-02-17 13:55:36,846 - INFO -       ‚úÖ 'Lageado de Ara√ßa√≠ba' ‚Üí 'Lageado': 4 registros\n",
      "2026-02-17 13:55:36,893 - INFO -       ‚úÖ 'Monte Verde Paulista' ‚Üí 'Monte Verde': 5 registros\n",
      "2026-02-17 13:55:36,946 - INFO -       ‚úÖ 'Aparecida de Monte Alto' ‚Üí 'Monte Alto': 5 registros\n",
      "2026-02-17 13:55:36,947 - INFO -    üìä Corre√ß√µes aplicadas: 44 registros\n",
      "2026-02-17 13:55:36,948 - INFO -    üîç Identificando cidades suspeitas...\n",
      "2026-02-17 13:55:37,019 - INFO -    üö® Cidades suspeitas identificadas: 59\n",
      "2026-02-17 13:55:37,021 - INFO -    üö® Registros suspeitos: 94\n",
      "2026-02-17 13:55:37,022 - INFO -    üìã Algumas cidades suspeitas:\n",
      "2026-02-17 13:55:37,023 - INFO -       ‚Ä¢ '√Ågua Vermelha': 3 registros\n",
      "2026-02-17 13:55:37,024 - INFO -       ‚Ä¢ 'Pracinha': 3 registros\n",
      "2026-02-17 13:55:37,025 - INFO -       ‚Ä¢ 'Cordeir?polis': 3 registros\n",
      "2026-02-17 13:55:37,026 - INFO -       ‚Ä¢ 'BiritibaMirim': 3 registros\n",
      "2026-02-17 13:55:37,026 - INFO -       ‚Ä¢ 'Igara?u do Tiet?': 3 registros\n",
      "2026-02-17 13:55:37,027 - INFO -       ‚Ä¢ 'Espig√£o': 3 registros\n",
      "2026-02-17 13:55:37,028 - INFO -       ‚Ä¢ 'Trabiju': 3 registros\n",
      "2026-02-17 13:55:37,028 - INFO -       ‚Ä¢ 'Iubatinga': 2 registros\n",
      "2026-02-17 13:55:37,029 - INFO -       ‚Ä¢ 'Nova Cana√£ Paulista': 2 registros\n",
      "2026-02-17 13:55:37,029 - INFO -       ‚Ä¢ 'Turmalina': 2 registros\n",
      "2026-02-17 13:55:37,030 - INFO -    ‚úÇÔ∏è Criando dataset limpo...\n",
      "2026-02-17 13:55:37,320 - INFO -    üìä RESULTADO DA LIMPEZA:\n",
      "2026-02-17 13:55:37,322 - INFO -       ‚Ä¢ Cidades: 760 ‚Üí 697 (-63)\n",
      "2026-02-17 13:55:37,323 - INFO -       ‚Ä¢ Registros: 649,651 ‚Üí 649,557 (-94)\n",
      "2026-02-17 13:55:37,324 - INFO -       ‚Ä¢ Diferen√ßa do esperado: +52\n",
      "2026-02-17 13:55:37,325 - WARNING -    ‚ö†Ô∏è Ainda 52 cidades acima do esperado - revisar limpeza\n",
      "2026-02-17 13:55:37,327 - INFO - ‚úÖ Limpeza de cidades SP conclu√≠da\n",
      "2026-02-17 13:55:37,361 - INFO - ‚úÖ Registros SP limpos: 649,557\n",
      "2026-02-17 13:55:37,401 - INFO - üó∫Ô∏è Criando recorte regional - S√£o Paulo...\n",
      "2026-02-17 13:55:37,472 - INFO - üìä Criando m√©tricas regionais...\n",
      "2026-02-17 13:55:37,782 - INFO - ‚úÖ Recorte regional criado: 649,557 registros\n",
      "2026-02-17 13:55:37,783 - INFO - üèôÔ∏è Cidades analisadas: 697\n",
      "2026-02-17 13:55:37,784 - INFO - üë• Criando recorte et√°rio...\n",
      "2026-02-17 13:55:37,952 - INFO - ‚úÖ An√°lise et√°ria criada: 7 faixas et√°rias\n",
      "2026-02-17 13:55:37,954 - INFO - üìä Top 3 faixas et√°rias:\n",
      "2026-02-17 13:55:37,955 - INFO -    ‚Ä¢ entre 31 a 40 anos: 213,440.0 reclama√ß√µes (32.86%)\n",
      "2026-02-17 13:55:37,957 - INFO -    ‚Ä¢ entre 41 a 50 anos: 158,354.0 reclama√ß√µes (24.38%)\n",
      "2026-02-17 13:55:37,958 - INFO -    ‚Ä¢ entre 21 a 30 anos: 143,990.0 reclama√ß√µes (22.17%)\n",
      "2026-02-17 13:55:37,960 - INFO - üè¢ Criando recorte setorial...\n",
      "2026-02-17 13:55:37,961 - INFO -    üìä Analisando segmentos de mercado...\n",
      "2026-02-17 13:55:38,054 - INFO -    üè¶ Analisando √°rea banc√°ria...\n",
      "2026-02-17 13:55:38,201 - INFO -    ‚ö†Ô∏è Analisando tipos de problemas...\n",
      "2026-02-17 13:55:38,338 - INFO -       ‚ö†Ô∏è Tipos de problemas identificados: 188\n",
      "2026-02-17 13:55:38,340 - INFO - ‚úÖ An√°lise setorial conclu√≠da\n",
      "2026-02-17 13:55:38,342 - INFO - üíæ Salvando recortes Gold...\n",
      "2026-02-17 13:55:48,058 - INFO -     Dataset SP: 649,557 registros\n",
      "2026-02-17 13:55:48,063 - INFO -     Ranking cidades: 697 cidades\n",
      "2026-02-17 13:55:48,079 - INFO -     An√°lise et√°ria: 7 faixas\n",
      "2026-02-17 13:55:48,083 - INFO -     Setorial segments: 45 registros\n",
      "2026-02-17 13:55:48,089 - INFO -     Setorial problems_general: 188 registros\n",
      "2026-02-17 13:55:48,169 - INFO -     Agibank SP: 4,006 registros\n",
      "2026-02-17 13:55:48,170 - INFO - ‚úÖ Todos os recortes salvos\n",
      "2026-02-17 13:55:48,171 - INFO - ======================================================================\n",
      "2026-02-17 13:55:48,172 - INFO -  RELAT√ìRIO GOLD DAG - RECORTES S√ÉO PAULO\n",
      "2026-02-17 13:55:48,173 - INFO -  Dura√ß√£o: 0:00:25.164285\n",
      "2026-02-17 13:55:48,174 - INFO -  Registros SP processados: 649,557\n",
      "2026-02-17 13:55:48,177 - INFO -  Registros Agibank SP: 4,006\n",
      "2026-02-17 13:55:48,178 - INFO -  Cidades SP analisadas: 697\n",
      "2026-02-17 13:55:48,179 - INFO -  Arquivos Gold gerados: 6\n",
      "2026-02-17 13:55:48,179 - INFO - ‚úÖ Gold DAG conclu√≠do - Recortes prontos para an√°lise!\n",
      "2026-02-17 13:55:48,181 - INFO - ======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gold DAG: SUCESSO!\n",
      "\n",
      "üìÅ Arquivos Gold gerados: 6\n",
      "----------------------------------------\n",
      "   üìÑ sp_agibank_only_v1.csv: 1.9 MB\n",
      "   üìÑ sp_analise_etaria_v1.csv: 0.0 MB\n",
      "   üìÑ sp_consumidor_completo_v1.csv: 289.6 MB\n",
      "   üìÑ sp_ranking_cidades_v1.csv: 0.0 MB\n",
      "   üìÑ sp_setorial_problems_general_v1.csv: 0.0 MB\n",
      "   üìÑ sp_setorial_segments_v1.csv: 0.0 MB\n",
      "\n",
      "üìä AN√ÅLISE DETALHADA DOS RECORTES:\n",
      "----------------------------------------\n",
      "üèôÔ∏è Dataset Principal SP:\n",
      "   ‚Ä¢ Colunas: 32\n",
      "   ‚Ä¢ Amostra shape: (1000, 32)\n",
      "   ‚Ä¢ Agibank na amostra: 17\n",
      "\n",
      "üó∫Ô∏è Ranking Cidades SP:\n",
      "   ‚Ä¢ Total cidades: 697\n",
      "   ‚Ä¢ Colunas: ['cidade', 'total_reclamacoes', 'reclamacoes_agibank', 'percentual_agibank', 'taxa_resposta_pct']\n",
      "   ‚Ä¢ Top 3 cidades:\n",
      "      1. 0: 227,446 reclama√ß√µes\n",
      "      2. 1: 20,522 reclama√ß√µes\n",
      "      3. 2: 18,330 reclama√ß√µes\n",
      "\n",
      "üë• An√°lise Et√°ria:\n",
      "   ‚Ä¢ Faixas et√°rias: 7\n",
      "   ‚Ä¢ Top 3 faixas:\n",
      "      1. 0: 213,440 reclama√ß√µes\n",
      "      2. 1: 158,354 reclama√ß√µes\n",
      "      3. 2: 143,990 reclama√ß√µes\n",
      "\n",
      "üè¶ Dataset Agibank SP:\n",
      "   ‚Ä¢ Arquivo existe: ‚úÖ\n",
      "   ‚Ä¢ Colunas: 32\n",
      "\n",
      "üéâ Todos os recortes foram gerados com sucesso!\n",
      "üìÇ Localiza√ß√£o: c:\\Users\\ana.leandro\\Desktop\\projeto_mediacao_bancaria\\notebooks\\..\\data\\gold\n",
      "\n",
      "============================================================\n",
      "üèÅ Teste Gold DAG conclu√≠do!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Teste completo do Gold DAG - Recortes SP\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from gold_clipping import gold_dag\n",
    "\n",
    "print(\"üß™ Testando Gold DAG - Recortes S√£o Paulo...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    result = gold_dag()\n",
    "    print(\"‚úÖ Gold DAG: SUCESSO!\")\n",
    "    \n",
    "    # Verificar arquivos gerados\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    \n",
    "    gold_path = Path(\"../data/gold\")\n",
    "    \n",
    "    if gold_path.exists():\n",
    "        gold_files = list(gold_path.glob(\"*.csv\"))\n",
    "        print(f\"\\nüìÅ Arquivos Gold gerados: {len(gold_files)}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for file in sorted(gold_files):\n",
    "            size_mb = file.stat().st_size / (1024*1024)\n",
    "            print(f\"   üìÑ {file.name}: {size_mb:.1f} MB\")\n",
    "        \n",
    "        # An√°lise detalhada dos principais arquivos\n",
    "        print(f\"\\nüìä AN√ÅLISE DETALHADA DOS RECORTES:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # 1. Dataset principal SP\n",
    "        main_file = gold_path / \"sp_consumidor_completo_v1.csv\"\n",
    "        if main_file.exists():\n",
    "            df_main = pd.read_csv(main_file, sep=';', nrows=1000)  # Sample\n",
    "            print(f\"üèôÔ∏è Dataset Principal SP:\")\n",
    "            print(f\"   ‚Ä¢ Colunas: {len(df_main.columns)}\")\n",
    "            print(f\"   ‚Ä¢ Amostra shape: {df_main.shape}\")\n",
    "            \n",
    "            if 'is_agibank' in df_main.columns:\n",
    "                agibank_sample = (df_main['is_agibank'] == True).sum()\n",
    "                print(f\"   ‚Ä¢ Agibank na amostra: {agibank_sample}\")\n",
    "        \n",
    "        # 2. Ranking de cidades\n",
    "        ranking_file = gold_path / \"sp_ranking_cidades_v1.csv\"\n",
    "        if ranking_file.exists():\n",
    "            df_ranking = pd.read_csv(ranking_file)\n",
    "            print(f\"\\nüó∫Ô∏è Ranking Cidades SP:\")\n",
    "            print(f\"   ‚Ä¢ Total cidades: {len(df_ranking)}\")\n",
    "            print(f\"   ‚Ä¢ Colunas: {list(df_ranking.columns)}\")\n",
    "            print(f\"   ‚Ä¢ Top 3 cidades:\")\n",
    "            for i, (city, data) in enumerate(df_ranking.head(3).iterrows()):\n",
    "                print(f\"      {i+1}. {city}: {data['total_reclamacoes']:,} reclama√ß√µes\")\n",
    "        \n",
    "        # 3. An√°lise et√°ria\n",
    "        age_file = gold_path / \"sp_analise_etaria_v1.csv\"\n",
    "        if age_file.exists():\n",
    "            df_age = pd.read_csv(age_file)\n",
    "            print(f\"\\nüë• An√°lise Et√°ria:\")\n",
    "            print(f\"   ‚Ä¢ Faixas et√°rias: {len(df_age)}\")\n",
    "            print(f\"   ‚Ä¢ Top 3 faixas:\")\n",
    "            for i, (age, data) in enumerate(df_age.head(3).iterrows()):\n",
    "                print(f\"      {i+1}. {age}: {data['total_reclamacoes']:,} reclama√ß√µes\")\n",
    "        \n",
    "        # 4. Dataset Agibank\n",
    "        agibank_file = gold_path / \"sp_agibank_only_v1.csv\"\n",
    "        if agibank_file.exists():\n",
    "            # S√≥ ler header para verificar\n",
    "            df_agibank_info = pd.read_csv(agibank_file, sep=';', nrows=0)\n",
    "            print(f\"\\nüè¶ Dataset Agibank SP:\")\n",
    "            print(f\"   ‚Ä¢ Arquivo existe: ‚úÖ\")\n",
    "            print(f\"   ‚Ä¢ Colunas: {len(df_agibank_info.columns)}\")\n",
    "        \n",
    "        print(f\"\\nüéâ Todos os recortes foram gerados com sucesso!\")\n",
    "        print(f\"üìÇ Localiza√ß√£o: {gold_path.absolute()}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Diret√≥rio gold n√£o foi criado!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro no teste: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÅ Teste Gold DAG conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f781d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivo criado com sucesso!\n",
      "üìÅ Localiza√ß√£o: ../data/gold/orientacoes_analise_bi.txt\n",
      "üìß Pronto para enviar para sua colega!\n"
     ]
    }
   ],
   "source": [
    "# Criar arquivo de orienta√ß√µes para a colega\n",
    "orientacoes_content = \"\"\"\n",
    "================================================================================\n",
    "                    ORIENTA√á√ïES PARA AN√ÅLISE DE BI\n",
    "                     Projeto Media√ß√£o Banc√°ria - Agibank\n",
    "================================================================================\n",
    "\n",
    "üéØ OBJETIVO DO PROJETO:\n",
    "Analisar reclama√ß√µes do Consumidor.gov.br focando em S√£o Paulo para:\n",
    "- Identificar principais dores dos clientes Agibank\n",
    "- Comparar Agibank com concorrentes do setor banc√°rio\n",
    "- Encontrar oportunidades de melhoria e expans√£o\n",
    "\n",
    "================================================================================\n",
    "üìÅ DATASETS DISPON√çVEIS PARA AN√ÅLISE\n",
    "================================================================================\n",
    "\n",
    "üìç LOCALIZA√á√ÉO DOS ARQUIVOS:\n",
    "c:\\\\Users\\\\ana.leandro\\\\Desktop\\\\projeto_mediacao_bancaria\\\\data\\\\gold\\\\\n",
    "\n",
    "üìä DATASETS PRINCIPAIS:\n",
    "\n",
    "1. üìÑ sp_consumidor_completo_v1.csv (289.6 MB)\n",
    "   ‚Ä¢ 649,557 registros de S√£o Paulo (limpos e validados)\n",
    "   ‚Ä¢ 32 colunas dispon√≠veis\n",
    "   ‚Ä¢ Cont√©m TODOS os dados para an√°lise explorat√≥ria\n",
    "   ‚Ä¢ Use este para an√°lises gerais e cruzamentos de dados\n",
    "\n",
    "2. üè¶ sp_agibank_only_v1.csv (1.9 MB)\n",
    "   ‚Ä¢ Aproximadamente 1,500-2,000 registros apenas do Agibank\n",
    "   ‚Ä¢ Mesmo formato do dataset principal\n",
    "   ‚Ä¢ Use para an√°lises espec√≠ficas do banco\n",
    "   ‚Ä¢ Perfeito para storytelling focado no Agibank\n",
    "\n",
    "3. üó∫Ô∏è sp_ranking_cidades_v1.csv\n",
    "   Colunas principais:\n",
    "   ‚Ä¢ cidade: Nome da cidade\n",
    "   ‚Ä¢ total_reclamacoes: Total de reclama√ß√µes por cidade\n",
    "   ‚Ä¢ reclamacoes_agibank: Quantas s√£o do Agibank\n",
    "   ‚Ä¢ percentual_agibank: % Agibank na cidade\n",
    "   ‚Ä¢ taxa_resposta_pct: % de reclama√ß√µes respondidas\n",
    "\n",
    "   üìä Use para:\n",
    "   - Mapas de calor por cidade\n",
    "   - Ranking de cidades problem√°ticas\n",
    "   - Comparar presen√ßa Agibank por regi√£o\n",
    "\n",
    "4. üë• sp_analise_etaria_v1.csv\n",
    "   Colunas principais:\n",
    "   ‚Ä¢ faixa_etaria: Faixa et√°ria do consumidor\n",
    "   ‚Ä¢ total_reclamacoes: Total por faixa et√°ria\n",
    "   ‚Ä¢ reclamacoes_agibank: Reclama√ß√µes Agibank por faixa\n",
    "   ‚Ä¢ percentual_total: % do total geral\n",
    "   ‚Ä¢ percentual_agibank: % Agibank na faixa et√°ria\n",
    "   ‚Ä¢ taxa_resposta_pct: Taxa de resposta por idade\n",
    "\n",
    "   üìä Use para:\n",
    "   - Perfil demogr√°fico dos clientes\n",
    "   - Identificar faixa et√°ria alvo do Agibank\n",
    "   - Comparar comportamento por idade\n",
    "\n",
    "5. üè¢ sp_setorial_segments_v1.csv\n",
    "   ‚Ä¢ An√°lise por segmento de mercado\n",
    "   ‚Ä¢ Identifica principais setores com reclama√ß√µes\n",
    "   ‚Ä¢ Posi√ß√£o do setor banc√°rio vs outros setores\n",
    "\n",
    "   üìä Use para:\n",
    "   - Contexto de mercado geral\n",
    "   - Benchmark setorial\n",
    "\n",
    "6. ‚ö†Ô∏è sp_setorial_problems_general_v1.csv\n",
    "   ‚Ä¢ Lista todos os tipos de problemas relatados\n",
    "   ‚Ä¢ Frequ√™ncia geral vs Agibank espec√≠fico\n",
    "   ‚Ä¢ Identifica principais dores dos clientes\n",
    "\n",
    "   üìä Use para:\n",
    "   - Identificar problemas mais cr√≠ticos\n",
    "   - Comparar Agibank vs mercado\n",
    "   - Priorizar melhorias de produto/servi√ßo\n",
    "\n",
    "================================================================================\n",
    "üéØ SUGEST√ïES DE AN√ÅLISES E VISUALIZA√á√ïES\n",
    "================================================================================\n",
    "\n",
    "üìà AN√ÅLISES PRIORIT√ÅRIAS:\n",
    "\n",
    "1. üèÜ TOP 10 CIDADES COM MAIS RECLAMA√á√ïES AGIBANK\n",
    "   - Gr√°fico de barras horizontal\n",
    "   - Identifica onde focar melhorias regionais\n",
    "   - Dataset: sp_ranking_cidades_v1.csv\n",
    "\n",
    "2. üë• PERFIL ET√ÅRIO: AGIBANK VS MERCADO\n",
    "   - Gr√°fico de barras comparativo\n",
    "   - Mostra diferen√ßas no perfil de clientes\n",
    "   - Dataset: sp_analise_etaria_v1.csv\n",
    "\n",
    "3. ‚ö†Ô∏è TOP 5 PROBLEMAS MAIS FREQUENTES NO AGIBANK\n",
    "   - Gr√°fico de pizza ou barras\n",
    "   - Prioriza a√ß√µes de melhoria\n",
    "   - Dataset: sp_setorial_problems_general_v1.csv\n",
    "\n",
    "4. üìä TAXA DE RESPOSTA: AGIBANK VS CONCORRENTES\n",
    "   - Gr√°fico de barras comparativo\n",
    "   - Avalia qualidade do atendimento\n",
    "   - Dataset: sp_ranking_cidades_v1.csv\n",
    "\n",
    "5. üó∫Ô∏è MAPA DE CALOR: CONCENTRA√á√ÉO AGIBANK EM SP\n",
    "   - Mapa interativo ou heatmap\n",
    "   - Identifica regi√µes de maior/menor presen√ßa\n",
    "   - Dataset: sp_ranking_cidades_v1.csv\n",
    "\n",
    "================================================================================\n",
    "üîç PERGUNTAS DE NEG√ìCIO PARA RESPONDER\n",
    "================================================================================\n",
    "\n",
    "üìã QUEST√ïES ESTRAT√âGICAS:\n",
    "\n",
    "1. üèôÔ∏è REGIONAL:\n",
    "   ‚Ä¢ Em quais cidades o Agibank tem mais problemas?\n",
    "   ‚Ä¢ Onde a taxa de resposta do Agibank √© menor?\n",
    "   ‚Ä¢ Quais regi√µes t√™m baixa presen√ßa Agibank (oportunidade)?\n",
    "\n",
    "2. üë• DEMOGR√ÅFICA:\n",
    "   ‚Ä¢ Qual faixa et√°ria reclama mais do Agibank?\n",
    "   ‚Ä¢ O perfil et√°rio do Agibank difere do mercado?\n",
    "   ‚Ä¢ Que faixa et√°ria o Agibank pode explorar mais?\n",
    "\n",
    "3. ‚ö†Ô∏è OPERACIONAL:\n",
    "   ‚Ä¢ Quais os principais problemas dos clientes Agibank?\n",
    "   ‚Ä¢ Esses problemas s√£o √∫nicos do Agibank ou do setor?\n",
    "   ‚Ä¢ Qual problema tem maior impacto no volume de reclama√ß√µes?\n",
    "\n",
    "4. üèÜ COMPETITIVA:\n",
    "   ‚Ä¢ O Agibank responde melhor ou pior que a concorr√™ncia?\n",
    "   ‚Ä¢ Em que aspectos o Agibank se destaca positivamente?\n",
    "   ‚Ä¢ Onde h√° oportunidade de melhoria vs concorrentes?\n",
    "\n",
    "5. üíº ESTRAT√âGICA:\n",
    "   ‚Ä¢ Onde o Agibank pode expandir com menor risco?\n",
    "   ‚Ä¢ Que segmento de cliente priorizar?\n",
    "   ‚Ä¢ Quais melhorias teriam maior impacto?\n",
    "\n",
    "================================================================================\n",
    "üìä DICAS T√âCNICAS PARA VISUALIZA√á√ÉO\n",
    "================================================================================\n",
    "\n",
    "üé® SUGEST√ïES DE GR√ÅFICOS:\n",
    "\n",
    "‚Ä¢ Mapas de Calor: Para distribui√ß√£o geogr√°fica\n",
    "‚Ä¢ Gr√°ficos de Barras: Para compara√ß√µes e rankings\n",
    "‚Ä¢ Gr√°ficos de Pizza: Para composi√ß√£o de problemas\n",
    "‚Ä¢ Gr√°ficos de Linha: Para tend√™ncias temporais (se usar datas)\n",
    "‚Ä¢ Dashboards Interativos: Para explora√ß√£o pelos stakeholders\n",
    "\n",
    "üîß FERRAMENTAS RECOMENDADAS:\n",
    "‚Ä¢ Power BI, Tableau, ou Python (matplotlib/seaborn)\n",
    "‚Ä¢ Excel para an√°lises r√°pidas\n",
    "‚Ä¢ Google Data Studio para dashboards web\n",
    "\n",
    "üìã ESTRUTURA DE APRESENTA√á√ÉO SUGERIDA:\n",
    "1. Contexto e Objetivos\n",
    "2. Vis√£o Geral dos Dados SP\n",
    "3. An√°lise Espec√≠fica Agibank\n",
    "4. Compara√ß√£o com Concorrentes\n",
    "5. Principais Achados e Oportunidades\n",
    "6. Recomenda√ß√µes Estrat√©gicas\n",
    "\n",
    "================================================================================\n",
    "üìû SUPORTE T√âCNICO\n",
    "================================================================================\n",
    "\n",
    "ü§ù CONTATO:\n",
    "Para d√∫vidas sobre os dados ou estrutura dos arquivos, entre em contato\n",
    "com a equipe de Engenharia de Dados do projeto.\n",
    "\n",
    "üìÖ DADOS ATUALIZADOS EM: Fevereiro 2026\n",
    "üîÑ VERS√ÉO DOS DATASETS: v1\n",
    "üìä TOTAL DE REGISTROS PROCESSADOS: 2.567.095 (Brasil) | 649.557 (SP)\n",
    "\n",
    "================================================================================\n",
    "                              BOA AN√ÅLISE! üöÄ\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# Salvar arquivo\n",
    "output_path = \"../data/gold/orientacoes_analise_bi.txt\"\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(orientacoes_content)\n",
    "\n",
    "print(\"‚úÖ Arquivo criado com sucesso!\")\n",
    "print(f\"üìÅ Localiza√ß√£o: {output_path}\")\n",
    "print(\"üìß Pronto para enviar para sua colega!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d27189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
