{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be616172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 08:58:15,224 - INFO - Iniciando DAG Bronze...\n",
      "2026-01-29 08:58:15,225 - INFO - Validando arquivos dispon√≠veis...\n",
      "2026-01-29 08:58:15,226 - INFO - Valida√ß√£o de arquivos conclu√≠da:\n",
      "2026-01-29 08:58:15,227 - INFO - Explorando estrutura: basecompleta2025-01.csv\n",
      "2026-01-29 08:58:15,258 - INFO -   Colunas: 1\n",
      "2026-01-29 08:58:15,259 - INFO -   Primeiras colunas: ['version https://git-lfs.github.com/spec/v1']\n",
      "2026-01-29 08:58:15,260 - INFO - Iniciando processamento Consumidor.gov...\n",
      "2026-01-29 08:58:15,261 - INFO -   Processando: basecompleta2025-01.csv\n",
      "2026-01-29 08:58:15,263 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,265 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,266 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,267 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,267 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,267 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-01.csv\n",
      "2026-01-29 08:58:15,270 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,271 - INFO -   basecompleta2025-01.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,272 - INFO -   Processando: basecompleta2025-02.csv\n",
      "2026-01-29 08:58:15,297 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,299 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,300 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,300 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,301 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,301 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-02.csv\n",
      "2026-01-29 08:58:15,303 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,304 - INFO -   basecompleta2025-02.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,304 - INFO -   Processando: basecompleta2025-03.csv\n",
      "2026-01-29 08:58:15,327 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,329 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,330 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,330 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,330 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,331 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-03.csv\n",
      "2026-01-29 08:58:15,332 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,333 - INFO -   basecompleta2025-03.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,333 - INFO -   Processando: basecompleta2025-04.csv\n",
      "2026-01-29 08:58:15,360 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,364 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,366 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,368 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,369 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,370 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-04.csv\n",
      "2026-01-29 08:58:15,374 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,377 - INFO -   basecompleta2025-04.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,380 - INFO -   Processando: basecompleta2025-05.csv\n",
      "2026-01-29 08:58:15,408 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,410 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,411 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,412 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,412 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,412 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-05.csv\n",
      "2026-01-29 08:58:15,414 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,415 - INFO -   basecompleta2025-05.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,415 - INFO -   Processando: basecompleta2025-06.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando Bronze DAG...\n",
      "Temos 12 arquivos do Consumidor.gov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 08:58:15,436 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,438 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,438 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,439 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,439 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,440 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-06.csv\n",
      "2026-01-29 08:58:15,444 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,445 - INFO -   basecompleta2025-06.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,446 - INFO -   Processando: basecompleta2025-07.csv\n",
      "2026-01-29 08:58:15,468 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,469 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,470 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,471 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,471 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,472 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-07.csv\n",
      "2026-01-29 08:58:15,474 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,475 - INFO -   basecompleta2025-07.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,476 - INFO -   Processando: basecompleta2025-08.csv\n",
      "2026-01-29 08:58:15,506 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,509 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,510 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,510 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,511 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,511 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-08.csv\n",
      "2026-01-29 08:58:15,512 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,513 - INFO -   basecompleta2025-08.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,513 - INFO -   Processando: basecompleta2025-09.csv\n",
      "2026-01-29 08:58:15,541 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,543 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,544 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,545 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,546 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,546 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-09.csv\n",
      "2026-01-29 08:58:15,547 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,548 - INFO -   basecompleta2025-09.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,548 - INFO -   Processando: basecompleta2025-10.csv\n",
      "2026-01-29 08:58:15,578 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,579 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,580 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,580 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,580 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,581 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-10.csv\n",
      "2026-01-29 08:58:15,583 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,583 - INFO -   basecompleta2025-10.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,584 - INFO -   Processando: basecompleta2025-11.csv\n",
      "2026-01-29 08:58:15,610 - ERROR -  Erro processando basecompleta2025-11.csv: Error tokenizing data. C error: Expected 3 fields in line 4, saw 5\n",
      "\n",
      "2026-01-29 08:58:15,612 - INFO -   Processando: basecompleta2025-12.csv\n",
      "2026-01-29 08:58:15,627 - INFO - Adicionando metadados...\n",
      "2026-01-29 08:58:15,629 - INFO - Metadados adicionados com sucessso\n",
      "2026-01-29 08:58:15,630 - INFO - Index(['data_source', 'file_origin', 'processed_at', 'file_month',\n",
      "       'is_agibank'],\n",
      "      dtype='object')\n",
      "2026-01-29 08:58:15,630 - INFO - Identificando registros Agibank...\n",
      "2026-01-29 08:58:15,631 - WARNING - Coluna de empresa n√£o identificada\n",
      "2026-01-29 08:58:15,631 - INFO - Executando verifica√ß√µes de qualidade: basecompleta2025-12.csv\n",
      "2026-01-29 08:58:15,633 - WARNING - Poucas linhas: 2 < 100\n",
      "2026-01-29 08:58:15,636 - INFO -   basecompleta2025-12.csv: 2 -> 2 registros\n",
      "2026-01-29 08:58:15,638 - INFO - Consumidor.gov processado 22 registros totais\n",
      "2026-01-29 08:58:15,640 - INFO - Salvando dados bronze: ../data/silver/consumidor_gov_bronze.csv\n",
      "2026-01-29 08:58:15,646 - INFO - Total de registros: 22\n",
      "2026-01-29 08:58:15,647 - INFO - Registro Agibank: 0\n",
      "2026-01-29 08:58:15,647 - INFO - Colunas: 7\n",
      "2026-01-29 08:58:15,648 - INFO - ----------------------------------------------------------------------\n",
      "2026-01-29 08:58:15,648 - INFO - RELAT√ìRIO BRONZE DAG\n",
      "\n",
      "2026-01-29 08:58:15,648 - INFO - Dura√ß√£o: 0:00:00.422659\n",
      "2026-01-29 08:58:15,649 - INFO - Registros processados: 22\n",
      "2026-01-29 08:58:15,649 - INFO - Registros Agibank: 0\n",
      "2026-01-29 08:58:15,649 - INFO - Issues de qualidade: 11\n",
      "2026-01-29 08:58:15,650 - INFO - \n",
      "DAG Bronze concluida com sucesso!\n",
      "2026-01-29 08:58:15,650 - INFO - ----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste do Bronze DAG: SUCESSO!\n",
      "Arquivo de sa√≠da n√£o encontrado!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Teste da camada Bronze\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from bronze_ingestion import bronze_dag\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testando Bronze DAG...\")\n",
    "    \n",
    "    try:\n",
    "        result = bronze_dag()\n",
    "        print(\"Teste do Bronze DAG: SUCESSO!\")\n",
    "        \n",
    "        # Verificar se o arquivo foi criado\n",
    "        output_file = Path(\"data/silver/consumidor_gov_bronze.csv\")\n",
    "        if output_file.exists():\n",
    "            print(f\"Arquivo criado: {output_file}\")\n",
    "            print(f\"Tamanho do arquivo: {output_file.stat().st_size / 1024:.2f} KB\")\n",
    "        else:\n",
    "            print(\"Arquivo de sa√≠da n√£o encontrado!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Teste falhou: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b691053",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261ffbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DIAGN√ìSTICO DOS ARQUIVOS\n",
      "==================================================\n",
      "\n",
      "üìÅ Arquivo: basecompleta2025-01.csv\n",
      "üìä Tamanho: 74551.34 KB\n",
      "üìÑ Primeiras linhas:\n",
      "   1: ÔªøGestor;Canal de Origem;Regi√£o;UF;Cidade;Sexo;Faixa Et√°ria;Ano Abertura;M√™s Abertura;Data Abertura;D...\n",
      "   2: Programa Estadual de Prote√ß√£o e Defesa do Consumidor;Plataforma Web;SE;MG;Belo Horizonte;M;entre 61 ...\n",
      "   3: Secretaria Adjunta de Prote√ß√£o e Defesa dos Direitos do Consumidor - PROCON-MT;Plataforma Web;CO;MT;...\n",
      "‚úÖ Arquivo parece ser CSV real\n",
      "\n",
      "üìÅ Arquivo: basecompleta2025-02.csv\n",
      "üìä Tamanho: 74420.38 KB\n",
      "üìÑ Primeiras linhas:\n",
      "   1: ÔªøGestor;Canal de Origem;Regi√£o;UF;Cidade;Sexo;Faixa Et√°ria;Ano Abertura;M√™s Abertura;Data Abertura;D...\n",
      "   2: Coordena√ß√£o Estadual do Procon de Rond√¥nia;Plataforma Web;N ;RO;Pimenta Bueno;F;entre 51 a 60 anos;2...\n",
      "   3: Secretaria de Estado de Defesa do Consumidor;Plataforma Web;SE;RJ;Belford Roxo;O;mais de 70 anos;202...\n",
      "‚úÖ Arquivo parece ser CSV real\n",
      "\n",
      "üìÅ Arquivo: basecompleta2025-03.csv\n",
      "üìä Tamanho: 66602.93 KB\n",
      "üìÑ Primeiras linhas:\n",
      "   1: ÔªøGestor;Canal de Origem;Regi√£o;UF;Cidade;Sexo;Faixa Et√°ria;Ano Abertura;M√™s Abertura;Data Abertura;D...\n",
      "   2: Funda√ß√£o de Prote√ß√£o e Defesa do Consumidor;Plataforma Web;SE;SP;Campinas;M;entre 31 a 40 anos;2025;...\n",
      "   3: Secretaria de Estado de Defesa do Consumidor;Plataforma Web;SE;RJ;Campos dos Goytacazes;M;entre 31 a...\n",
      "‚úÖ Arquivo parece ser CSV real\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "def diagnose_files():\n",
    "    \"\"\"Diagnosticar arquivos na pasta bronze\"\"\"\n",
    "    \n",
    "    consumidor_files = glob.glob(\"../data/bronze/consumidor_gov/*.csv\")\n",
    "    \n",
    "    print(\"üîç DIAGN√ìSTICO DOS ARQUIVOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for file_path in consumidor_files[:3]:  # Verificar apenas 3 arquivos\n",
    "        print(f\"\\nüìÅ Arquivo: {Path(file_path).name}\")\n",
    "        print(f\"üìä Tamanho: {Path(file_path).stat().st_size / 1024:.2f} KB\")\n",
    "        \n",
    "        # Ler primeiras linhas\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                first_lines = [f.readline().strip() for _ in range(3)]\n",
    "            \n",
    "            print(\"üìÑ Primeiras linhas:\")\n",
    "            for i, line in enumerate(first_lines, 1):\n",
    "                print(f\"   {i}: {line[:100]}...\")\n",
    "                \n",
    "            # Verificar se √© Git LFS\n",
    "            if \"git-lfs\" in first_lines[0]:\n",
    "                print(\"‚ö†Ô∏è  PROBLEMA: Este √© um ponteiro Git LFS, n√£o o arquivo real!\")\n",
    "                return False\n",
    "            else:\n",
    "                print(\"‚úÖ Arquivo parece ser CSV real\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro lendo arquivo: {e}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Executar diagn√≥stico\n",
    "diagnose_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f1dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Erro lendo basecompleta2025-01.csv: Error tokenizing data. C error: Expected 4 fields in line 4, saw 5\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-02.csv: Error tokenizing data. C error: Expected 5 fields in line 23, saw 8\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-03.csv: Error tokenizing data. C error: Expected 3 fields in line 3, saw 4\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-04.csv: Error tokenizing data. C error: Expected 3 fields in line 8, saw 5\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-05.csv: Error tokenizing data. C error: Expected 3 fields in line 6, saw 5\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-06.csv: Error tokenizing data. C error: Expected 3 fields in line 11, saw 5\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-07.csv: Error tokenizing data. C error: Expected 3 fields in line 3, saw 4\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-08.csv: Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-09.csv: Error tokenizing data. C error: Expected 3 fields in line 3, saw 5\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-10.csv: Error tokenizing data. C error: Expected 8 fields in line 114, saw 9\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-11.csv: Error tokenizing data. C error: Expected 3 fields in line 4, saw 5\n",
      "\n",
      "‚ùå Erro lendo basecompleta2025-12.csv: Error tokenizing data. C error: Expected 2 fields in line 3, saw 8\n",
      "\n",
      "‚ö†Ô∏è Nenhum arquivo CSV v√°lido encontrado!\n"
     ]
    }
   ],
   "source": [
    "def test_real_csv():\n",
    "\n",
    "    \"\"\"Testar se conseguimos ler um CSV real\"\"\"\n",
    "    \n",
    "    # Verificar se existe algum arquivo que n√£o seja Git LFS\n",
    "    consumidor_files = glob.glob(\"../data/bronze/consumidor_gov/*.csv\")\n",
    "    \n",
    "    for file_path in consumidor_files:\n",
    "        try:\n",
    "            # Tentar ler primeiras linhas\n",
    "            df_sample = pd.read_csv(file_path)\n",
    "            \n",
    "            if len(df_sample.columns) > 1:  # Se tem mais de 1 coluna, provavelmente √© real\n",
    "                print(f\"‚úÖ Arquivo CSV v√°lido encontrado: {Path(file_path).name}\")\n",
    "                print(f\"üìä Colunas: {list(df_sample.columns)}\")\n",
    "                print(f\"üìä Shape: {df_sample.shape}\")\n",
    "                return file_path\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro lendo {Path(file_path).name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"‚ö†Ô∏è Nenhum arquivo CSV v√°lido encontrado!\")\n",
    "    return None\n",
    "\n",
    "test_real_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c3e934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Colunas: ['Gestor', 'Canal de Origem', 'Regi√£o', 'UF', 'Cidade', 'Sexo', 'Faixa Et√°ria', 'Ano Abertura', 'M√™s Abertura', 'Data Abertura', 'Data Resposta', 'Data An√°lise', 'Data Recusa', 'Data Finaliza√ß√£o', 'Prazo Resposta', 'Prazo Analise Gestor', 'Tempo Resposta', 'Nome Fantasia', 'Segmento de Mercado', '√Årea', 'Assunto', 'Grupo Problema', 'Problema', 'Como Comprou Contratou', 'Procurou Empresa', 'Respondida', 'Situa√ß√£o', 'Avalia√ß√£o Reclama√ß√£o', 'Nota do Consumidor', 'An√°lise da Recusa']\n",
      "üìä Shape: (172466, 30)\n",
      "üìä Primeiras 3 colunas: ['Gestor', 'Canal de Origem', 'Regi√£o']\n",
      "üè¶ Registros Agibank encontrados: 1098\n"
     ]
    }
   ],
   "source": [
    "# C√©lula de teste corrigida\n",
    "consumidor_file = \"../data/bronze/consumidor_gov/basecompleta2025-01.csv\"\n",
    "\n",
    "# Usar sep=';' e encoding correto\n",
    "df_test = pd.read_csv(consumidor_file, sep=';', encoding='utf-8')\n",
    "\n",
    "print(f\"üìä Colunas: {list(df_test.columns)}\")\n",
    "print(f\"üìä Shape: {df_test.shape}\")\n",
    "print(f\"üìä Primeiras 3 colunas: {list(df_test.columns)[:3]}\")\n",
    "\n",
    "# Verificar se tem dados do Agibank\n",
    "if 'Nome Fantasia' in df_test.columns:\n",
    "    agibank_mask = df_test['Nome Fantasia'].str.contains('AGIBANK|AGI BANK', case=False, na=False)\n",
    "    print(f\"üè¶ Registros Agibank encontrados: {agibank_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552029d",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
